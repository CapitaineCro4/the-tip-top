name: CI/CD Pipeline with Backup and Deploy

on:
  push:
    branches:
      - develop
      - main
  pull_request:
    branches:
      - develop
      - main
  schedule:
    - cron: "0 0 * * 0" # Tous les dimanches Ã  minuit UTC
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write
  issues: write
  pull-requests: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Front Dependencies
        working-directory: ./front
        run: yarn install --frozen-lockfile

      - name: Build Front
        working-directory: ./front
        run: yarn build || { echo "Front build failed"; exit 1; }

      - name: Install API Dependencies
        working-directory: ./api
        run: yarn install --frozen-lockfile

      - name: Build API
        working-directory: ./api
        run: yarn build || { echo "API build failed"; exit 1; }

      - name: Upload Build Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            front/.next/
            api/dist/
          retention-days: 1

  test:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Front Dependencies
        working-directory: ./front
        run: yarn install --frozen-lockfile

      - name: Run Front Tests
        working-directory: ./front
        run: yarn test --coverage
        env:
          NODE_ENV: test

      - name: Install API Dependencies
        working-directory: ./api
        run: yarn install --frozen-lockfile

      - name: Run API Tests
        working-directory: ./api
        run: yarn test:e2e
        env:
          NODE_ENV: test

      - name: Store Test Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports
          path: |
            ./api/coverage/
            ./front/coverage/

  docker:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Build Artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts
          path: .

      - name: Restore Build Artifacts
        run: |
          mkdir -p front/.next api/dist
          cp -r .next/* front/.next/
          cp -r dist/* api/dist/

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and Push API Image
        run: |
          docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/the-tip-top-api:latest ./api
          docker push ${{ secrets.DOCKERHUB_USERNAME }}/the-tip-top-api:latest

      - name: Build and Push Front Image
        run: |
          docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/the-tip-top-front:latest ./front
          docker push ${{ secrets.DOCKERHUB_USERNAME }}/the-tip-top-front:latest

  deploy-develop:
    needs: docker
    if: github.ref == 'refs/heads/develop'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to Develop
        env:
          VPS_HOST: "46.202.132.119"
          VPS_USER: "root"
          VPS_PASSWORD: ${{ secrets.VPS_PASSWORD }}
        run: |
          sshpass -p "$VPS_PASSWORD" ssh -o StrictHostKeyChecking=no $VPS_USER@$VPS_HOST << 'EOF'
            echo "Deploying to develop..."
            mkdir -p /root/the-tip-top-dev
            cd /root/the-tip-top-dev
            git fetch origin develop
            git reset --hard origin/develop
            echo "ENV=dev" > .env
            echo "DOCKERHUB_USERNAME=${{ secrets.DOCKERHUB_USERNAME }}" >> .env
            echo "API_PORT=3002" >> .env
            echo "DATABASE_URL=postgresql://admin:admin@postgres_db-dev:5432/mydatabase?schema=public" >> .env
            echo "JWT_SECRET=secret" >> .env
            echo "NEXT_PUBLIC_API_URL=https://dev.dsp5-archi-f24a-15m-g4.fr/back" >> .env
            echo "NEXT_PUBLIC_FRONTEND_URL=https://dev.dsp5-archi-f24a-15m-g4.fr" >> .env
            docker-compose pull
            docker-compose up -d
            docker system prune -f
            docker volume prune -f
            echo "Deployment to develop finished!"
          EOF

  deploy-production:
    needs: docker
    if: github.event_name == 'workflow_dispatch' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://dsp5-archi-f24a-15m-g4.fr
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to Production
        env:
          VPS_HOST: "46.202.132.119"
          VPS_USER: "root"
          VPS_PASSWORD: ${{ secrets.VPS_PASSWORD }}
        run: |
          sshpass -p "$VPS_PASSWORD" ssh -o StrictHostKeyChecking=no $VPS_USER@$VPS_HOST << 'EOF'
            echo "Deploying to production..."
            mkdir -p /root/the-tip-top-prod
            cd /root/the-tip-top-prod
            git fetch origin main
            git reset --hard origin/main
            echo "ENV=prod" > .env
            echo "DOCKERHUB_USERNAME=${{ secrets.DOCKERHUB_USERNAME }}" >> .env
            echo "API_PORT=3102" >> .env
            echo "DATABASE_URL=postgresql://admin:admin@postgres_db-prod:5432/mydatabase?schema=public" >> .env
            echo "JWT_SECRET=${{ secrets.JWT_SECRET }}" >> .env
            echo "NEXT_PUBLIC_API_URL=https://dsp5-archi-f24a-15m-g4.fr/back" >> .env
            echo "NEXT_PUBLIC_FRONTEND_URL=https://dsp5-archi-f24a-15m-g4.fr" >> .env
            echo "GOOGLE_CLIENT_ID=${{ secrets.GOOGLE_CLIENT_ID }}" >> .env
            echo "GOOGLE_CLIENT_SECRET=${{ secrets.GOOGLE_CLIENT_SECRET }}" >> .env
            echo "FACEBOOK_CLIENT_ID=${{ secrets.FACEBOOK_CLIENT_ID }}" >> .env
            echo "FACEBOOK_CLIENT_SECRET=${{ secrets.FACEBOOK_CLIENT_SECRET }}" >> .env
            echo "SMTP_HOST=${{ secrets.SMTP_HOST }}" >> .env
            echo "SMTP_PORT=${{ secrets.SMTP_PORT }}" >> .env
            echo "SMTP_USER=${{ secrets.SMTP_USER }}" >> .env
            echo "SMTP_PASS=${{ secrets.SMTP_PASS }}" >> .env
            echo "SMTP_FROM=${{ secrets.SMTP_FROM }}" >> .env
            docker-compose pull
            docker-compose up -d
            docker system prune -f
            docker volume prune -f
            echo "Deployment to production finished!"
          EOF

  backup-production:
    needs: docker
    if: github.event_name == 'schedule' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install Google Drive API client
        run: pip install google-auth-httplib2 google-auth-oauthlib google-api-python-client

      - name: Backup Production Database
        env:
          VPS_HOST: "46.202.132.119"
          VPS_USER: "root"
          VPS_PASSWORD: ${{ secrets.VPS_PASSWORD }}
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
          FOLDER_ID: "1YOHfU8s4J2wy5Wl1-d_jYY9wZs_-eqoO"
        run: |
          sshpass -p "$VPS_PASSWORD" ssh -o StrictHostKeyChecking=no $VPS_USER@$VPS_HOST << 'EOF'
            cd /root/the-tip-top-prod
            BACKUP_NAME="db-backup-$(date +%Y%m%d-%H%M%S).sql"
            docker exec postgres_db-prod pg_dump -U admin mydatabase > "$BACKUP_NAME"
            echo "Database backup created: $BACKUP_NAME"
          EOF
          sshpass -p "$VPS_PASSWORD" scp $VPS_USER@$VPS_HOST:/root/the-tip-top-prod/$BACKUP_NAME .
          echo "$GOOGLE_CREDENTIALS" > credentials.json
          cat << 'EOF' > upload_to_drive.py
          import os
          from google.oauth2.service_account import Credentials
          from googleapiclient.discovery import build
          from googleapiclient.http import MediaFileUpload

          backup_name = os.environ.get("BACKUP_NAME")
          folder_id = os.environ.get("FOLDER_ID")
          if not backup_name or not folder_id:
              raise ValueError(f"Missing variables. BACKUP_NAME: {backup_name}, FOLDER_ID: {folder_id}")
          if not os.path.exists(backup_name):
              raise FileNotFoundError(f"Backup file not found: {backup_name}")

          creds = Credentials.from_service_account_file("credentials.json")
          drive_service = build("drive", "v3", credentials=creds)
          file_metadata = {"name": backup_name, "parents": [folder_id]}
          media = MediaFileUpload(backup_name, resumable=True)
          file = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()
          print(f"File ID: {file.get('id')}")
          EOF
          export BACKUP_NAME="db-backup-$(date +%Y%m%d-%H%M%S).sql"
          python upload_to_drive.py
          rm -f credentials.json $BACKUP_NAME

  coverage-test:
    needs: test
    runs-on: ubuntu-latest
    environment:
      name: Coverage test visualization page
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Download Test Reports
        uses: actions/download-artifact@v4
        with:
          name: test-reports
          path: coverage-reports

      - name: Upload Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: "coverage-reports/front/coverage/lcov-report"

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4